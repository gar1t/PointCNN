# ===================================================================
# Classification - base config
# ===================================================================

- config: cls-base
  params:
    train-data-path: data/train_files.txt
    val-data-path: data/test_files.txt
  operations:
    train:
      description: Train model for classification
      main:
        train_val_cls
          --model pointcnn_cls
          --path {{train-data-path}}
          --path_val {{val-data-path}}
          --save_folder .
          --no_timestamp_folder
          --no_code_backup
          --log -
      requires: prepared-data
      compare:
        - =epochs
        - =setting
        - max t_1_acc/val as accuracy
      flags:
        $import:
          - epochs
          - batch_size
        setting:
          description: Setting to use for operation
          choices: []
          required: yes
          allow-other: yes

# ===================================================================
# Classification - ScanNet
# ===================================================================

- model: cls-scannet
  description: PointCNN classifier on ScanNet (not currently supported)
  operations:
    train:
      description: Placeholder for ScanNet train
      main:
        guild.fail 'This operation is not currently implemented. Refer'
                   'to https://github.com/yangyanli/PointCNN#scannet for'
                   'manual steps.'

# ===================================================================
# Classification - ModelNet
# ===================================================================

- model: cls-modelnet
  description: PointCNN classifier on Princeton ModelNet 40 dataset
  extends: cls-base
  operations:
    train:
      requires: modelnet-data
      flags:
        setting:
          default: modelnet_x3_l4
          choices:
            - modelnet_x3_l4_aligned
            - modelnet_x3_l4_aligned_w_fts
            - modelnet_x3_l4_no_X
            - modelnet_x3_l4_no_X_wider
            - modelnet_x3_l4
            - modelnet_x3_l4_w_fts
            - modelnet_x3_l4_yxz
            - modelnet_x3_l5_no_X
  resources:
    modelnet-data:
      path: data
      sources:
        - url: https://shapenet.cs.stanford.edu/media/modelnet40_ply_hdf5_2048.zip
          sha256: 07670e237db72ece0f723b9abb571534c9ad655a6456b389646587dc72bb8bae
          select: modelnet40_ply_hdf5_2048/.*

# ===================================================================
# Classification - TU Berlin
# ===================================================================

- model: cls-tu-berlin
  description: PointCNN classifier on TU Berlin dataset
  extends: cls-base
  operations:
    prepare-data:
      description: Prepare data for training
      requires: tu-berlin-data
      main:
        data_conversions/prepare_tu_berlin_data
          --folder tu_berlin
          --augment
          --create-train-test
    train:
      flags:
        setting:
          default: tu_berlin_x3_l4
          choices:
            - tu_berlin_x3_l4
  resources:
    tu-berlin-data:
      path: tu_berlin
      sources:
        - url: http://cybertron.cg.tu-berlin.de/eitz/projects/classifysketch/sketches_svg.zip
          sha256: 5c1d10dcfbfd808a842a1c6ab6122ccc104c1556b4b50294a352e73ce197c81a
          select: svg/.*
    prepared-data:
      path: data
      sources:
        - operation: prepare-data
          select: .*\.(txt|h5)

# ===================================================================
# Classification - Quick Draw
# ===================================================================

- model: cls-quick-draw
  description: PointCNN classifier on Quick Draw dataset
  extends: cls-base
  params:
    train-data-path: data
    val-data-path: ''
  operations:
    prepare-data:
      description: Prepare data for training
      main: data_conversions/download_datasets --dataset quick_draw --folder .
    train:
      flags:
        setting:
          default: quick_draw_full_x2_l6
          choices:
            - quick_draw_full_x2_l6
  resources:
    prepared-data:
      path: data
      sources:
        - operation: prepare-data
          select: quick_draw/zips/.*

# ===================================================================
# Classification - MNIST
# ===================================================================

- model: cls-mnist
  description: PointCNN classifier on MNIST dataset
  extends: cls-base
  operations:
    prepare-data:
      description: Prepare data for training
      main: data_conversions/prepare_mnist_data --folder mnist
      requires: mnist-data
    train:
      flags:
        setting:
          default: mnist_x2_l4
          choices:
            - mnist_x2_l4
  resources:
    mnist-data:
      path: mnist
      sources:
        - url: http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz
          sha256: 440fcabf73cc546fa21475e81ea370265605f56be210a4024d2ca8f203523609
        - url: http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz
          sha256: 3552534a0a558bbed6aed32b30c495cca23d567ec52cac8be1a0730e8010255c
        - url: http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz
          sha256: 8d422c7b0a1c1c79245a5bcf07fe86e33eeafee792b84584aec276f5a2dbc4e6
        - url: http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz
          sha256: f7ae60f92e00ec6debd23a6088c31dbd2371eca3ffa0defaefb259924204aec6
    prepared-data:
      path: data
      sources:
        - operation: prepare-data
          select: .*\.(txt|h5)

# ===================================================================
# Classification - CIFAR-10
# ===================================================================

- model: cls-cifar10
  description: PointCNN classifier on CIFAR-10 dataset
  extends: cls-base
  operations:
    prepare-data:
      description: Prepare data for training
      main: data_conversions/prepare_cifar10_data --folder cifar10
      requires: cifar10-data
    train:
      flags:
        setting:
          default: cifar10_x3_l4
          choices:
            - cifar10_x3_l4
  resources:
    cifar10-data:
      path: cifar10
      sources:
        - url: https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz
          sha256: 6d958be074577803d12ecdefd02955f39262c83c16fe9348329d7fe0b5c001ce
          select: cifar-10-batches-py/.*
    prepared-data:
      path: data
      sources:
        - operation: prepare-data
          select: .*\.(txt|h5)

# ===================================================================
# Segmentation - base config
# ===================================================================

- config: sampling-support
  resources:
    tf-sampling:
      sources:
        - file: sampling
          post-process: (cd sampling && bash tf_sampling_compile.sh)

# ===================================================================
# Segmentation - ShapeNet
# ===================================================================

- model: seg-shapenet
  description: PointCNN segmentation on ShapeNet dataset
  extends: sampling-support
  operations:
    prepare-data:
      description: Prepare data for training
      main: data_conversions/prepare_partseg_data --folder .
      requires: shapenet-data
      flags:
        $import:
          - save_ply
    train:
      description: Train model for segmentation
      main:
        train_val_seg
          --model pointcnn_seg
          --filelist data/train_val_files.txt
          --filelist_val data/test_files.txt
          --save_folder .
          --no_timestamp_folder
          --no_code_backup
          --log -
      requires:
        - prepared-data
        - tf-sampling
      compare:
        - =epochs
        - =setting
        - max t_1_acc/val as accuracy
      flags:
        $import:
          - epochs
          - batch_size
        setting:
          description: Setting to use for operation
          default: shapenet_x8_2048_fps
          choices:
            - shapenet_x8_2048_fps
          required: yes
          allow-other: yes
    test:
      description: Test trained model
      main:
        test_shapenet_seg
          --filelist data/test_files.txt
          --category data/categories.txt
          --data_folder data/test_data
          --model pointcnn_seg
          --load_ckpt ckpts/iter-${step}
      requires:
        - prepared-data
        - checkpoints
      flags:
        $include:
          - seg-shapenet:train#setting
        $import:
          - repeat_num
          - sample_num
        step:
          description: Checkpoint step to test
          required: yes
          arg-skip: yes
    evaluate:
      description: Evaluate tests
      main:
        evaluation/eval_shapenet_seg
          --folder_gt data/test_label
          --folder_pred test_data_pred_nips_1
          --part_avg
      requires:
        - prepared-data
        - tests
  resources:
    shapenet-data:
      sources:
        - url: https://shapenet.cs.stanford.edu/iccv17/partseg/train_data.zip
          sha256: 2641c724e5d21400580bf5122fe442f259ce4bcabb45e68c42f31da6560c446f
        - url: https://shapenet.cs.stanford.edu/iccv17/partseg/train_label.zip
          sha256: c197602742b3e6222686789f7d8c32370319d5bf30ccb3341c81046248bcec60
        - url: https://shapenet.cs.stanford.edu/iccv17/partseg/val_data.zip
          sha256: 54d7fa806a6b22cfecac68e07014bb4d7739df162ca13448434d1ba3318480ce
        - url: https://shapenet.cs.stanford.edu/iccv17/partseg/val_label.zip
          sha256: c03ddb5be9410e8d204238b0de0817e6ced403110d134f70b080381b7584ab7e
        - url: https://shapenet.cs.stanford.edu/iccv17/partseg/test_data.zip
          sha256: 8c5864c5b0c2f421649d3901ef0afc0200bafb934df9a4b17263e699510032b3
        - url: https://shapenet.cs.stanford.edu/iccv17/partseg/test_label.zip
          sha256: 27c86b0445f2bafb5c4a03cfc78ee55c764d617e422d663eef704a3d60b9db58
    prepared-data:
      path: data
      sources:
        - operation: prepare-data
          select:
            - .*\.(txt|h5)
            - test_data
            - test_label
    checkpoints:
      sources:
        - operation: train
          select: ckpts
    tests:
      sources:
        - operation: test
          select: data/test_data_pred_nips_[0-9]+

# ===================================================================
# Segmentation - S3DIS
# ===================================================================

- model: seg-s3dis
  description: PointCNN segmentation on S3DIS dataset
  extends: sampling-support
  operations:
    prepare-labels:
      description: Prepare labels
      main: data_conversions/prepare_s3dis_label --folder .
      flags:
        data:
          description: Path to Stanford3dDataset_v1.2_Aligned_Version
          required: yes
    prepare-data:
      description: Prepare data
      main: data_conversions/prepare_s3dis_data --folder s3dis
      requires: prepared-labels
      flags:
        $import:
          - block_size
          - grid_size
          - save_ply
    prepare-filelists:
      description: Prepare file lists
      main: data_conversions/prepare_s3dis_filelists --folder s3dis
      requires: prepared-data
      flags:
        $import:
          - h5_num
          - repeat_num
    train:
      main:
        train_val_seg
          --filelist s3dis/train_files_for_val_on_Area_${area}.txt
          --filelist_val s3dis/val_files_Area_${area}.txt
          --save_folder .
          --model pointcnn_seg
          --no_timestamp_folder
          --no_code_backup
          --log -
      requires:
        - prepared-data
        - tf-sampling
      flags:
        area:
          description: S3DIS area for operation
          choices: [1, 2, 3, 4, 5, 6]
          default: 1
          required: yes
          arg-skip: yes
        setting:
          description: Setting to use for operation
          default: s3dis_x8_2048_fps
          choices:
            - s3dis_x8_2048_fps
          allow-other: yes
        $import:
          - epochs
          - batch_size
    test:
      description: Test trained model
      main:
        test_general_seg
          --filelist s3dis/val_files_Area_${area}.txt
          --model pointcnn_seg
          --load_ckpt ckpts/iter-${step}
      requires:
        - prepared-filelists
        - checkpoints
      flags:
        $include:
          - seg-s3dis:train#area
          - seg-s3dis:train#setting
        $import:
          - repeat_num
          - sample_num
        step:
          description: Checkpoint step to test
          required: yes
          arg-skip: yes

    merge-predictions:
      description: Merge predictions
      main: evaluation/s3dis_merge --datafolder s3dis/Area_${area}
      requires:
        - tests
      flags:
        $include:
          - seg-s3dis:train#area
    evaluate:
      description: Evaluate tests
      main: evaluation/eval_s3dis --data s3dis
      requires:
        - prepared-filelist
        - merged-predictions
  resources:
    prepared-labels:
      path: s3dis
      sources:
        - operation: prepare-labels
          select: Area_[0-9]+
    prepared-data:
      sources:
        - operation: prepare-data
          select: s3dis
    prepared-filelist:
      sources:
        - operation: prepare-filelists
    checkpoints:
      sources:
        - operation: train
          select: ckpts
    tests:
      sources:
        - operation: test
          select: s3dis
    merged-predictions:
      sources:
        - operation: merge-predictions
          select: s3dis

# ===================================================================
# Segmentation - ScanNet
# ===================================================================

- model: seg-scannet
  description: PointCNN segmentation on ScanNet (not currently supported)
  operations:
    train:
      description: Placeholder for ScanNet train
      main:
        guild.fail 'This operation is not currently implemented. Refer'
                   'to https://github.com/yangyanli/PointCNN#scannet-1 for'
                   'manual steps.'

# ===================================================================
# Segmentation - Semantic3D
# ===================================================================

- model: seg-semantic3d
  description: PointCNN segmentation on Semantic3D
  operations:
    download-data:
      description: Download data files
      exec: >
        bash -ec "
          which 7z || (echo 'ERROR: 7z is required for this operation' && false)
          bash download_semantic3d.sh .
          bash un7z_semantic3d.sh .
        "
      requires: download-scripts
    prepare-data:
      description: Prepare semantic-8 benchmark data
      main: data_conversions/prepare_semantic3d_data --folder .
      requires: semantic3d-raw
      flags:
        $import:
          - max_point_num
          - block_size
          - grid_size
          - save_ply
    prepare-filelists:
      description: Prepare semantic-8 file lists
      main: data_conversions/prepare_semantic3d_filelists --folder semantic3d
      requires: semantic3d-data
      flags:
        $import:
          - h5_num
          - repeat_num
  resources:
    download-scripts:
      sources:
        - data_conversions/download_semantic3d.sh
        - data_conversions/un7z_semantic3d.sh
